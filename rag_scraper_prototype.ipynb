{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e628bed7",
   "metadata": {},
   "source": [
    "# RAG Scraper Prototype\n",
    "\n",
    "**Author**  \n",
    "- Tilak Parajuli\n",
    "\n",
    "**All required links, videos, and other materials mentioned are in this drive link:**  \n",
    "👉 [Google Drive Folder](https://drive.google.com/drive/folders/1yu0zuPXnAHFB1I9dqubjR2q3rSZlSf0P?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c35ec82",
   "metadata": {},
   "source": [
    "# RAG-Based Company Knowledge Assistant\n",
    "\n",
    "This notebook demonstrates a prototype of a Retrieval-Augmented Generation (RAG) system using web content from the Fusemachines website. We will:\n",
    "- Scrape job listings using **Selenium + XPath**\n",
    "- Preprocess the scraped data into chunks\n",
    "- Embed the data using a transformer model via `ollama`\n",
    "- Retrieve relevant chunks with vector search (cosine similarity)\n",
    "- Generate responses using an LLM (via `ollama`)\n",
    "\n",
    "**Tools**:\n",
    "- Selenium (for scraping)\n",
    "- Ollama (for embeddings and generation)\n",
    "- Cosine similarity (for retrieval)\n",
    "\n",
    "Inspired by the Hugging Face article [Code a simple RAG from scratch](https://huggingface.co/blog/ngxson/make-your-own-rag), this notebook is adapted for real-world use cases involving dynamic, web-based knowledge sources.\n",
    "\n",
    "## Prerequisites\n",
    "- Install `ollama` from [ollama.com](https://ollama.com).\n",
    "- Pull the required models:\n",
    "  ```bash\n",
    "  ollama pull hf.co/CompendiumLabs/bge-base-en-v1.5-gguf\n",
    "  ollama pull hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2974504",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de2f9e77",
   "metadata": {},
   "source": [
    "## Scrape Text\n",
    "- We start by scraping job listings from the Fusemachines careers page using Selenium with Firefox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f32ac770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5a92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66a46ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "def scrape_fusemachines_jobs():\n",
    "    \"\"\"\n",
    "    Scrapes job listings from Fusemachines careers page using Firefox.\n",
    "    \n",
    "    XPaths:\n",
    "    COMPANY_BUTTON_XPATH = \"//button[@id='company']\"\n",
    "    CAREERS_LINK_XPATH = \"//a[@href='/company/careers/']\"\n",
    "    JOB_LISTINGS_XPATH = \"//div[@id='jazzhr']//div[contains(@class, 'row py-3')]\"\n",
    "    JOB_TITLE_XPATH = \".//div[contains(@class, 'col-md-6')]//div[@class='bold-s']\"\n",
    "    JOB_LOCATION_XPATH = \".//div[contains(@class, 'col-md-4')]//div[@class='c-dark-grey']\"\n",
    "    \"\"\"\n",
    "    # Set up Firefox options\n",
    "    options = Options()\n",
    "    # options.add_argument(\"--headless\")  # Uncomment for headless mode\n",
    "    \n",
    "    # Initialize Firefox driver\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    \n",
    "    try:\n",
    "        # Maximize browser window\n",
    "        driver.maximize_window()\n",
    "        \n",
    "        # Navigate to base URL\n",
    "        driver.get(\"https://fusemachines.com/\")\n",
    "        \n",
    "        # Wait for and click COMPANY dropdown\n",
    "        company_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[@id='company']\"))\n",
    "        )\n",
    "        company_button.click()\n",
    "        \n",
    "        # Wait for and click Careers link\n",
    "        careers_link = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//a[@href='/company/careers/']\"))\n",
    "        )\n",
    "        careers_link.click()\n",
    "        \n",
    "        # Wait for job listings to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"jazzhr\"))\n",
    "        )\n",
    "        \n",
    "        # Get all job listings\n",
    "        job_rows = driver.find_elements(By.XPATH, \"//div[@id='jazzhr']//div[contains(@class, 'row py-3')]\")\n",
    "        jobs = []\n",
    "        \n",
    "        for row in job_rows:\n",
    "            # Get job title\n",
    "            title = row.find_element(By.XPATH, \".//div[contains(@class, 'col-md-6')]//div[@class='bold-s']\").text\n",
    "            # Get location\n",
    "            location = row.find_element(By.XPATH, \".//div[contains(@class, 'col-md-4')]//div[@class='c-dark-grey']\").text\n",
    "            jobs.append({\"title\": title, \"location\": location})\n",
    "        \n",
    "        # Print results\n",
    "        print(\"Careers at Fusemachines\")\n",
    "        print(\"Available Jobs:\")\n",
    "        for job in jobs:\n",
    "            print(f\"- {job['title']} ({job['location']})\")\n",
    "        \n",
    "        return jobs\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf898c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     scrape_fusemachines_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872be5a",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- We preprocess the scraped job listings to create text chunks suitable for embedding. Each job listing (title and location) is combined into a single chunk for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7696d1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Careers at Fusemachines\n",
      "Available Jobs:\n",
      "- Senior Product Manager (Buenos Aires, Argentina)\n",
      "- UI/UX Designer (Buenos Aires, Argentina)\n",
      "- Data Scientist (Argentina)\n",
      "- Sr. Data Analyst (Buenos Aires, Argentina)\n",
      "- Senior Fullstack Engineer (Lead) (Argentina)\n",
      "- Senior Product Manager (Brasilia, Brazil)\n",
      "- UI/UX Designer (Brasília, Brazil)\n",
      "- Sr. Machine Learning Engineer (Brazil)\n",
      "- Data Scientist (Brazil)\n",
      "- Sr. Data Analyst (Brasilia, Brazil)\n",
      "- Senior Fullstack Engineer (Lead) (Brazil)\n",
      "- Senior Technical Project Manager (Brazil)\n",
      "- Sr. Machine Learning Engineer (Toronto, Canada)\n",
      "- Senior Product Manager (Chile)\n",
      "- UI/UX Designer (Bogota, Colombia)\n",
      "- Talent Acquisition Partner (Colombia)\n",
      "- Sr. Machine Learning Engineer (Colombia)\n",
      "- Data Scientist (Colombia)\n",
      "- Sr. Data Analyst (Bogota, Colombia)\n",
      "- Senior Fullstack Engineer (Lead) (Colombia)\n",
      "- Sr. Software Engineer (Pune, India)\n",
      "- Sr. Data Engineer Azure Databricks (Pune, India)\n",
      "- QA Testing Engineer (Pune, India)\n",
      "- Power Platform Engineer (Pune, India)\n",
      "- Sr. Machine Learning Engineer (India)\n",
      "- Sr. Data Scientist (Pune, India)\n",
      "- QA Automation Engineer (Pune, India)\n",
      "- ML Engineer (Pune, India)\n",
      "- Middleware Engineer (Pune, India)\n",
      "- Sr. Data Engineer (Pune, India)\n",
      "- UI/UX Designer (Mexico City, Mexico)\n",
      "- Senior Product Manager (Mexico City, Mexico)\n",
      "- Talent Acquisition Partner (Mexico)\n",
      "- Sr. Machine Learning Engineer (Mexico)\n",
      "- Data Scientist (Mexico)\n",
      "- Sr. Data Analyst (Mexico City, Mexico)\n",
      "- Data Engineer (LLM Applications) (Mexico City, Mexico)\n",
      "- Senior Data Scientist (Mexico City, Mexico)\n",
      "- Sr. Software Engineer (Kathmandu, Nepal)\n",
      "- Assistant Finance Manager (Kathmandu, Nepal)\n",
      "- Sr. Accounting Officer (Kathmandu, Nepal)\n",
      "- Sr. Data Engineer Azure Databricks (Kathmandu, Nepal)\n",
      "- QA Testing Engineer (Kathmandu, Nepal)\n",
      "- Power Platform Engineer (Kathmandu, Nepal)\n",
      "- Sr. Machine Learning Engineer (Kathmandu, Nepal)\n",
      "- Sr. Data Scientist (Kathmandu, Nepal)\n",
      "- Data Scientist (Kathmandu, Nepal)\n",
      "- ML Engineer (Kathmandu, Nepal)\n",
      "- Middleware Engineer (Kathmandu, Nepal)\n",
      "- Sr. Data Engineer Azure Databricks (Islamabad, Pakistan)\n",
      "- QA Testing Engineer (Islamabad, Pakistan)\n",
      "- Power Platform Engineer (Islamabad, Pakistan)\n",
      "- Sr. Machine Learning Engineer (Pakistan)\n",
      "- Sr. Data Analyst (Islamabad, Pakistan)\n",
      "- ML Engineer (Islamabad, Pakistan)\n",
      "- Middleware Engineer (Islamabad, Pakistan)\n",
      "- Data Scientist (Islamabad, Pakistan)\n",
      "- Senior Product Manager (Peru)\n",
      "- Accounting Manager (Philippines)\n",
      "- Power Platform Engineer (London, United Kingdom)\n",
      "- Chief Financial Officer (New York, United States)\n",
      "- Senior MLOps Engineer (Washington, D.C, United States)\n",
      "- VP of Finance (New York, United States)\n",
      "Created 63 chunks for embedding:\n",
      "Chunk 1: Senior Product Manager in Buenos Aires, Argentina\n",
      "Chunk 2: UI/UX Designer in Buenos Aires, Argentina\n",
      "Chunk 3: Data Scientist in Argentina\n",
      "Chunk 4: Sr. Data Analyst in Buenos Aires, Argentina\n",
      "Chunk 5: Senior Fullstack Engineer (Lead) in Argentina\n",
      "Chunk 6: Senior Product Manager in Brasilia, Brazil\n",
      "Chunk 7: UI/UX Designer in Brasília, Brazil\n",
      "Chunk 8: Sr. Machine Learning Engineer in Brazil\n",
      "Chunk 9: Data Scientist in Brazil\n",
      "Chunk 10: Sr. Data Analyst in Brasilia, Brazil\n",
      "Chunk 11: Senior Fullstack Engineer (Lead) in Brazil\n",
      "Chunk 12: Senior Technical Project Manager in Brazil\n",
      "Chunk 13: Sr. Machine Learning Engineer in Toronto, Canada\n",
      "Chunk 14: Senior Product Manager in Chile\n",
      "Chunk 15: UI/UX Designer in Bogota, Colombia\n",
      "Chunk 16: Talent Acquisition Partner in Colombia\n",
      "Chunk 17: Sr. Machine Learning Engineer in Colombia\n",
      "Chunk 18: Data Scientist in Colombia\n",
      "Chunk 19: Sr. Data Analyst in Bogota, Colombia\n",
      "Chunk 20: Senior Fullstack Engineer (Lead) in Colombia\n",
      "Chunk 21: Sr. Software Engineer in Pune, India\n",
      "Chunk 22: Sr. Data Engineer Azure Databricks in Pune, India\n",
      "Chunk 23: QA Testing Engineer in Pune, India\n",
      "Chunk 24: Power Platform Engineer in Pune, India\n",
      "Chunk 25: Sr. Machine Learning Engineer in India\n",
      "Chunk 26: Sr. Data Scientist in Pune, India\n",
      "Chunk 27: QA Automation Engineer in Pune, India\n",
      "Chunk 28: ML Engineer in Pune, India\n",
      "Chunk 29: Middleware Engineer in Pune, India\n",
      "Chunk 30: Sr. Data Engineer in Pune, India\n",
      "Chunk 31: UI/UX Designer in Mexico City, Mexico\n",
      "Chunk 32: Senior Product Manager in Mexico City, Mexico\n",
      "Chunk 33: Talent Acquisition Partner in Mexico\n",
      "Chunk 34: Sr. Machine Learning Engineer in Mexico\n",
      "Chunk 35: Data Scientist in Mexico\n",
      "Chunk 36: Sr. Data Analyst in Mexico City, Mexico\n",
      "Chunk 37: Data Engineer (LLM Applications) in Mexico City, Mexico\n",
      "Chunk 38: Senior Data Scientist in Mexico City, Mexico\n",
      "Chunk 39: Sr. Software Engineer in Kathmandu, Nepal\n",
      "Chunk 40: Assistant Finance Manager in Kathmandu, Nepal\n",
      "Chunk 41: Sr. Accounting Officer in Kathmandu, Nepal\n",
      "Chunk 42: Sr. Data Engineer Azure Databricks in Kathmandu, Nepal\n",
      "Chunk 43: QA Testing Engineer in Kathmandu, Nepal\n",
      "Chunk 44: Power Platform Engineer in Kathmandu, Nepal\n",
      "Chunk 45: Sr. Machine Learning Engineer in Kathmandu, Nepal\n",
      "Chunk 46: Sr. Data Scientist in Kathmandu, Nepal\n",
      "Chunk 47: Data Scientist in Kathmandu, Nepal\n",
      "Chunk 48: ML Engineer in Kathmandu, Nepal\n",
      "Chunk 49: Middleware Engineer in Kathmandu, Nepal\n",
      "Chunk 50: Sr. Data Engineer Azure Databricks in Islamabad, Pakistan\n",
      "Chunk 51: QA Testing Engineer in Islamabad, Pakistan\n",
      "Chunk 52: Power Platform Engineer in Islamabad, Pakistan\n",
      "Chunk 53: Sr. Machine Learning Engineer in Pakistan\n",
      "Chunk 54: Sr. Data Analyst in Islamabad, Pakistan\n",
      "Chunk 55: ML Engineer in Islamabad, Pakistan\n",
      "Chunk 56: Middleware Engineer in Islamabad, Pakistan\n",
      "Chunk 57: Data Scientist in Islamabad, Pakistan\n",
      "Chunk 58: Senior Product Manager in Peru\n",
      "Chunk 59: Accounting Manager in Philippines\n",
      "Chunk 60: Power Platform Engineer in London, United Kingdom\n",
      "Chunk 61: Chief Financial Officer in New York, United States\n",
      "Chunk 62: Senior MLOps Engineer in Washington, D.C, United States\n",
      "Chunk 63: VP of Finance in New York, United States\n"
     ]
    }
   ],
   "source": [
    "def preprocess_jobs(jobs):\n",
    "    \"\"\"\n",
    "    Convert job listings into text chunks for embedding.\n",
    "    Each chunk is a string combining job title and location.\n",
    "    \"\"\"\n",
    "    chunks = [f\"{job['title']} in {job['location']}\" for job in jobs]\n",
    "    return chunks\n",
    "\n",
    "# Example usage (run after scraping)\n",
    "jobs = scrape_fusemachines_jobs()\n",
    "chunks = preprocess_jobs(jobs)\n",
    "print(f\"Created {len(chunks)} chunks for embedding:\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"Chunk {i}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20b548",
   "metadata": {},
   "source": [
    "## Embedding Text Chunks\n",
    "\n",
    "- We use the bge-base-en-v1.5-gguf model via ollama to generate embeddings for each chunk and store them in an in-memory vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4415af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 74aebb552ea7... 100% ▕████████████████▏  68 MB                         \u001b[K\n",
      "pulling b1899e715228... 100% ▕████████████████▏  399 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# !pip install ollama\n",
    "!ollama pull hf.co/CompendiumLabs/bge-base-en-v1.5-gguf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d088878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 6f85a640a97c... 100% ▕████████████████▏ 807 MB                         \u001b[K\n",
      "pulling 948af2743fc7... 100% ▕████████████████▏ 1.5 KB                         \u001b[K\n",
      "pulling 6c0b08d96525... 100% ▕████████████████▏   65 B                         \u001b[K\n",
      "pulling 4549919ff315... 100% ▕████████████████▏  551 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f85f8157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded chunk: Senior Product Manager in Buenos Aires, Argentina\n",
      "Processed 1/63 chunks\n",
      "Embedded chunk: UI/UX Designer in Buenos Aires, Argentina\n",
      "Processed 2/63 chunks\n",
      "Embedded chunk: Data Scientist in Argentina\n",
      "Processed 3/63 chunks\n",
      "Embedded chunk: Sr. Data Analyst in Buenos Aires, Argentina\n",
      "Processed 4/63 chunks\n",
      "Embedded chunk: Senior Fullstack Engineer (Lead) in Argentina\n",
      "Processed 5/63 chunks\n",
      "Embedded chunk: Senior Product Manager in Brasilia, Brazil\n",
      "Processed 6/63 chunks\n",
      "Embedded chunk: UI/UX Designer in Brasília, Brazil\n",
      "Processed 7/63 chunks\n",
      "Embedded chunk: Sr. Machine Learning Engineer in Brazil\n",
      "Processed 8/63 chunks\n",
      "Embedded chunk: Data Scientist in Brazil\n",
      "Processed 9/63 chunks\n",
      "Embedded chunk: Sr. Data Analyst in Brasilia, Brazil\n",
      "Processed 10/63 chunks\n",
      "Embedded chunk: Senior Fullstack Engineer (Lead) in Brazil\n",
      "Processed 11/63 chunks\n",
      "Embedded chunk: Senior Technical Project Manager in Brazil\n",
      "Processed 12/63 chunks\n",
      "Embedded chunk: Sr. Machine Learning Engineer in Toronto, Canada\n",
      "Processed 13/63 chunks\n",
      "Embedded chunk: Senior Product Manager in Chile\n",
      "Processed 14/63 chunks\n",
      "Embedded chunk: UI/UX Designer in Bogota, Colombia\n",
      "Processed 15/63 chunks\n",
      "Embedded chunk: Talent Acquisition Partner in Colombia\n",
      "Processed 16/63 chunks\n",
      "Embedded chunk: Sr. Machine Learning Engineer in Colombia\n",
      "Processed 17/63 chunks\n",
      "Embedded chunk: Data Scientist in Colombia\n",
      "Processed 18/63 chunks\n",
      "Embedded chunk: Sr. Data Analyst in Bogota, Colombia\n",
      "Processed 19/63 chunks\n",
      "Embedded chunk: Senior Fullstack Engineer (Lead) in Colombia\n",
      "Processed 20/63 chunks\n",
      "Embedded chunk: Sr. Software Engineer in Pune, India\n",
      "Processed 21/63 chunks\n",
      "Embedded chunk: Sr. Data Engineer Azure Databricks in Pune, India\n",
      "Processed 22/63 chunks\n",
      "Embedded chunk: QA Testing Engineer in Pune, India\n",
      "Processed 23/63 chunks\n",
      "Embedded chunk: Power Platform Engineer in Pune, India\n",
      "Processed 24/63 chunks\n",
      "Embedded chunk: Sr. Machine Learning Engineer in India\n",
      "Processed 25/63 chunks\n",
      "Embedded chunk: Sr. Data Scientist in Pune, India\n",
      "Processed 26/63 chunks\n",
      "Embedded chunk: QA Automation Engineer in Pune, India\n",
      "Processed 27/63 chunks\n",
      "Embedded chunk: ML Engineer in Pune, India\n",
      "Processed 28/63 chunks\n",
      "Embedded chunk: Middleware Engineer in Pune, India\n",
      "Processed 29/63 chunks\n",
      "Embedded chunk: Sr. Data Engineer in Pune, India\n",
      "Processed 30/63 chunks\n",
      "Embedded chunk: UI/UX Designer in Mexico City, Mexico\n",
      "Processed 31/63 chunks\n",
      "Embedded chunk: Senior Product Manager in Mexico City, Mexico\n",
      "Processed 32/63 chunks\n",
      "Embedded chunk: Talent Acquisition Partner in Mexico\n",
      "Processed 33/63 chunks\n",
      "Embedded chunk: Sr. Machine Learning Engineer in Mexico\n",
      "Processed 34/63 chunks\n",
      "Embedded chunk: Data Scientist in Mexico\n",
      "Processed 35/63 chunks\n",
      "Embedded chunk: Sr. Data Analyst in Mexico City, Mexico\n",
      "Processed 36/63 chunks\n",
      "Embedded chunk: Data Engineer (LLM Applications) in Mexico City, Mexico\n",
      "Processed 37/63 chunks\n",
      "Embedded chunk: Senior Data Scientist in Mexico City, Mexico\n",
      "Processed 38/63 chunks\n",
      "Embedded chunk: Sr. Software Engineer in Kathmandu, Nepal\n",
      "Processed 39/63 chunks\n",
      "Embedded chunk: Assistant Finance Manager in Kathmandu, Nepal\n",
      "Processed 40/63 chunks\n",
      "Embedded chunk: Sr. Accounting Officer in Kathmandu, Nepal\n",
      "Processed 41/63 chunks\n",
      "Embedded chunk: Sr. Data Engineer Azure Databricks in Kathmandu, Nepal\n",
      "Processed 42/63 chunks\n",
      "Embedded chunk: QA Testing Engineer in Kathmandu, Nepal\n",
      "Processed 43/63 chunks\n",
      "Embedded chunk: Power Platform Engineer in Kathmandu, Nepal\n",
      "Processed 44/63 chunks\n",
      "Embedded chunk: Sr. Machine Learning Engineer in Kathmandu, Nepal\n",
      "Processed 45/63 chunks\n",
      "Embedded chunk: Sr. Data Scientist in Kathmandu, Nepal\n",
      "Processed 46/63 chunks\n",
      "Embedded chunk: Data Scientist in Kathmandu, Nepal\n",
      "Processed 47/63 chunks\n",
      "Embedded chunk: ML Engineer in Kathmandu, Nepal\n",
      "Processed 48/63 chunks\n",
      "Embedded chunk: Middleware Engineer in Kathmandu, Nepal\n",
      "Processed 49/63 chunks\n",
      "Embedded chunk: Sr. Data Engineer Azure Databricks in Islamabad, Pakistan\n",
      "Processed 50/63 chunks\n",
      "Embedded chunk: QA Testing Engineer in Islamabad, Pakistan\n",
      "Processed 51/63 chunks\n",
      "Embedded chunk: Power Platform Engineer in Islamabad, Pakistan\n",
      "Processed 52/63 chunks\n",
      "Embedded chunk: Sr. Machine Learning Engineer in Pakistan\n",
      "Processed 53/63 chunks\n",
      "Embedded chunk: Sr. Data Analyst in Islamabad, Pakistan\n",
      "Processed 54/63 chunks\n",
      "Embedded chunk: ML Engineer in Islamabad, Pakistan\n",
      "Processed 55/63 chunks\n",
      "Embedded chunk: Middleware Engineer in Islamabad, Pakistan\n",
      "Processed 56/63 chunks\n",
      "Embedded chunk: Data Scientist in Islamabad, Pakistan\n",
      "Processed 57/63 chunks\n",
      "Embedded chunk: Senior Product Manager in Peru\n",
      "Processed 58/63 chunks\n",
      "Embedded chunk: Accounting Manager in Philippines\n",
      "Processed 59/63 chunks\n",
      "Embedded chunk: Power Platform Engineer in London, United Kingdom\n",
      "Processed 60/63 chunks\n",
      "Embedded chunk: Chief Financial Officer in New York, United States\n",
      "Processed 61/63 chunks\n",
      "Embedded chunk: Senior MLOps Engineer in Washington, D.C, United States\n",
      "Processed 62/63 chunks\n",
      "Embedded chunk: VP of Finance in New York, United States\n",
      "Processed 63/63 chunks\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Model names\n",
    "EMBEDDING_MODEL = 'hf.co/CompendiumLabs/bge-base-en-v1.5-gguf'\n",
    "LANGUAGE_MODEL = 'hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF'\n",
    "\n",
    "# In-memory vector database: list of (chunk, embedding) tuples\n",
    "VECTOR_DB = []\n",
    "\n",
    "def add_chunk_to_database(chunk):\n",
    "    \"\"\"Add a chunk and its embedding to the vector database.\"\"\"\n",
    "    try:\n",
    "        embedding = ollama.embed(model=EMBEDDING_MODEL, input=chunk)['embeddings'][0]\n",
    "        VECTOR_DB.append((chunk, embedding))\n",
    "        print(f\"Embedded chunk: {chunk}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error embedding chunk '{chunk}': {e}\")\n",
    "\n",
    "# Index all chunks\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    add_chunk_to_database(chunk)\n",
    "    print(f\"Processed {i}/{len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67be5af0",
   "metadata": {},
   "source": [
    "## Implementing Similarity Search\n",
    "- We implement a retrieval function using cosine similarity to find the top N most relevant chunks for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9347c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example retrieval for query: Are there any Data Scientist or AI related jobs open at fusemachines canada?\n",
      " - (similarity: 0.78) Sr. Machine Learning Engineer in Toronto, Canada\n",
      " - (similarity: 0.68) Data Scientist in Argentina\n",
      " - (similarity: 0.67) Data Scientist in Kathmandu, Nepal\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    dot_product = sum(x * y for x, y in zip(a, b))\n",
    "    norm_a = sum(x ** 2 for x in a) ** 0.5\n",
    "    norm_b = sum(x ** 2 for x in b) ** 0.5\n",
    "    return dot_product / (norm_a * norm_b) if norm_a and norm_b else 0\n",
    "\n",
    "def retrieve(query, top_n=3):\n",
    "    \"\"\"Retrieve top N most relevant chunks based on query.\"\"\"\n",
    "    try:\n",
    "        query_embedding = ollama.embed(model=EMBEDDING_MODEL, input=query)['embeddings'][0]\n",
    "        similarities = []\n",
    "        for chunk, embedding in VECTOR_DB:\n",
    "            similarity = cosine_similarity(query_embedding, embedding)\n",
    "            similarities.append((chunk, similarity))\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return similarities[:top_n]\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving query '{query}': {e}\")\n",
    "        return []\n",
    "\n",
    "# Example retrieval\n",
    "query = \"Are there any Data Scientist or AI related jobs open at fusemachines canada?\"\n",
    "retrieved = retrieve(query)\n",
    "print(\"\\nExample retrieval for query:\", query)\n",
    "for chunk, similarity in retrieved:\n",
    "    print(f\" - (similarity: {similarity:.2f}) {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38c95a",
   "metadata": {},
   "source": [
    "## Inference: Response Generation with Language Model\n",
    "- We use the Llama-3.2-1B-Instruct-GGUF model to generate responses based on the retrieved chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ededc9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot response:\n",
      "Unfortunately, I don't have real-time access to current job openings on Fusemachines. However, I can suggest some options to help you find the information you're looking for:\n",
      "\n",
      "1. **Visit the Fusemachines website**: You can check their official job board or career section to see if they have any data scientist or AI-related jobs available.\n",
      "2. **Job search platforms**: Websites like Indeed, LinkedIn, and Glassdoor may also have Fusemachines' job listings. Try searching for \"Fusemachines\" along with the desired job title (e.g., Data Scientist).\n",
      "3. **Contact Fusemachines directly**: You can reach out to Fusemachines' HR department or a specific hiring manager to inquire about available data scientist or AI-related positions.\n",
      "\n",
      "Regarding Sr. Machine Learning Engineer, I couldn't find any information on this role at Fusemachines. If you're interested in applying for the position, it's likely that they have other openings for senior engineers with different expertise.\n",
      "\n",
      "For Data Scientist positions in specific countries (Argentina and Kathmandu), I found one job listing:\n",
      "\n",
      "- **Data Scientist** - Kathmandu, Nepal\n",
      "  - Job Title: Data Scientist\n",
      "  - Company: [Company Name]\n",
      "  - Location: Kathmandu, Nepal\n",
      "\n",
      "Please note that this is just one example of a job opening in the country you specified. Fusemachines might have other openings or postings on their website or other platforms.\n",
      "\n",
      "If you'd like to explore more job opportunities at Fusemachines, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "def generate_response(query, retrieved_knowledge):\n",
    "    \"\"\"Generate a response using the language model and retrieved knowledge.\"\"\"\n",
    "    instruction_prompt = f\"\"\"You are a helpful chatbot providing information about job openings at Fusemachines.\n",
    "Use only the following job listings to answer the question. Don't make up any new information:\n",
    "{'\\n'.join([f' - {chunk}' for chunk, similarity in retrieved_knowledge])}\n",
    "\"\"\"\n",
    "    try:\n",
    "        stream = ollama.chat(\n",
    "            model=LANGUAGE_MODEL,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': instruction_prompt},\n",
    "                {'role': 'user', 'content': query},\n",
    "            ],\n",
    "            stream=True,\n",
    "        )\n",
    "        print('Chatbot response:')\n",
    "        response = ''\n",
    "        for chunk in stream:\n",
    "            content = chunk['message']['content']\n",
    "            print(content, end='', flush=True)\n",
    "            response += content\n",
    "        print()  # New line after response\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response for query '{query}': {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Example generation\n",
    "response = generate_response(query, retrieved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916322a6",
   "metadata": {},
   "source": [
    "## Testing and Validation\n",
    "- We test the RAG system with a set of queries to validate its performance and ensure it retrieves relevant jobs and generates accurate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c1b1e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing query: What data scientist jobs are available?\n",
      "Retrieved job listings:\n",
      " - (similarity: 0.77) Data Scientist in Kathmandu, Nepal\n",
      " - (similarity: 0.74) Data Scientist in Argentina\n",
      " - (similarity: 0.73) Data Scientist in Brazil\n",
      "Chatbot response:\n",
      "Unfortunately, I don't have any data on specific jobs that match your criteria (Kathmandu, Nepal; Argentina; or Brazil). However, I can provide you with general information about data science job openings at Fusemachines.\n",
      "\n",
      "Fusemachines is a company that specializes in machine learning and artificial intelligence solutions. They often hire data scientists to work on various projects, including data engineering, modeling, and deployment.\n",
      "\n",
      "As of my knowledge cutoff, here are some job categories that might be relevant:\n",
      "\n",
      "* Data Scientist: We occasionally have openings for skilled data scientists who can build and deploy models using popular machine learning libraries.\n",
      "* Data Engineer: Fusemachines also hires data engineers to help design, develop, and maintain large-scale data systems.\n",
      "* Machine Learning Engineer: This role often involves working on complex machine learning projects, including model development, deployment, and maintenance.\n",
      "\n",
      "To find out about specific job openings or get more information about the company's current hiring needs, I recommend visiting Fusemachines' website (you can try searching for their career page) or reaching out to them directly.\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing query: Are there any jobs in Canada?\n",
      "Retrieved job listings:\n",
      " - (similarity: 0.59) Sr. Machine Learning Engineer in Toronto, Canada\n",
      " - (similarity: 0.48) Sr. Data Analyst in Brasilia, Brazil\n",
      " - (similarity: 0.47) Sr. Machine Learning Engineer in Brazil\n",
      "Chatbot response:\n",
      "Based on my knowledge cutoff, I can confirm that the following job listing is currently available:\n",
      "\n",
      "- Sr. Machine Learning Engineer in Toronto, Canada\n",
      "\n",
      "Please note that job listings are subject to change and may not be available at the time of inquiry. You may want to check the company's website or other job boards for more information.\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing query: Tell me about software engineer positions\n",
      "Retrieved job listings:\n",
      " - (similarity: 0.69) Sr. Software Engineer in Kathmandu, Nepal\n",
      " - (similarity: 0.67) Sr. Software Engineer in Pune, India\n",
      " - (similarity: 0.62) Middleware Engineer in Kathmandu, Nepal\n",
      "Chatbot response:\n",
      "I can provide you with general information about software engineer positions.\n",
      "\n",
      "As a helpful chatbot, I don't have any specific job listings to share, but I can tell you that here are some common types of software engineer roles:\n",
      "\n",
      "1. **Front-end Developer**: Responsible for building user interfaces and client-side logic using HTML, CSS, JavaScript, and frameworks like React or Angular.\n",
      "2. **Back-end Developer**: Focuses on designing and developing server-side logic, database integration, API connectivity, and middleware using programming languages like Java, Python, Ruby, or C#.\n",
      "3. **DevOps Engineer**: Ensures the smooth operation of software systems by managing infrastructure, deployment, and monitoring, often working closely with developers and operations teams.\n",
      "4. **Machine Learning/Machine Intelligence Engineer**: Develops and deploys machine learning models to solve real-world problems using programming languages like Python, R, or Julia.\n",
      "5. **Quality Assurance (QA) Engineer**: Tests software applications to ensure they meet quality standards and work efficiently.\n",
      "\n",
      "If you're interested in applying for one of these roles at Fusemachines, I recommend checking their job listings on the website for available positions.\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing query: What roles are available in Nepal?\n",
      "Retrieved job listings:\n",
      " - (similarity: 0.69) Sr. Accounting Officer in Kathmandu, Nepal\n",
      " - (similarity: 0.68) Assistant Finance Manager in Kathmandu, Nepal\n",
      " - (similarity: 0.67) Sr. Software Engineer in Kathmandu, Nepal\n",
      "Chatbot response:\n",
      "Unfortunately, I need to inform you that the job listings you provided earlier are not currently active or available. They were likely created as test data or examples of job openings.\n",
      "\n",
      "However, I can suggest some ways for you to find current job openings at Fusemachines:\n",
      "\n",
      "1. Visit our website: You can check our career page on our website (if it exists) for the latest job openings and apply online.\n",
      "2. Contact us directly: Reach out to our HR team or career development department via email or phone to inquire about available positions and submit your application.\n",
      "3. Check job search websites: Websites like Indeed, LinkedIn, Glassdoor, and Monster may have current job openings at Fusemachines that you can view and apply for.\n",
      "\n",
      "I hope this helps!\n",
      "--------------------------------------------------\n",
      "\n",
      "Interactive Testing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mInteractive Testing\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     query = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAsk about Fusemachines job openings (or type \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m to quit): \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query.lower() == \u001b[33m'\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Fellowship 2025/Week 1/Assignment/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py:1282\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1280\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Fellowship 2025/Week 1/Assignment/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py:1325\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1323\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1324\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1327\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def test_rag_system():\n",
    "    \"\"\"Test the RAG system with sample queries.\"\"\"\n",
    "    test_queries = [\n",
    "        \"What data scientist jobs are available?\",\n",
    "        \"Are there any jobs in Canada?\",\n",
    "        \"Tell me about software engineer positions\",\n",
    "        \"What roles are available in Nepal?\",\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\nTesting query: {query}\")\n",
    "        print(\"Retrieved job listings:\")\n",
    "        retrieved = retrieve(query)\n",
    "        for chunk, similarity in retrieved:\n",
    "            print(f\" - (similarity: {similarity:.2f}) {chunk}\")\n",
    "        generate_response(query, retrieved)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Run tests\n",
    "test_rag_system()\n",
    "\n",
    "# Interactive loop for further testing\n",
    "print(\"\\nInteractive Testing\")\n",
    "while True:\n",
    "    query = input(\"Ask about Fusemachines job openings (or type 'exit' to quit): \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "    print(\"\\nRetrieved job listings:\")\n",
    "    retrieved = retrieve(query)\n",
    "    for chunk, similarity in retrieved:\n",
    "        print(f\" - (similarity: {similarity:.2f}) {chunk}\")\n",
    "    generate_response(query, retrieved)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f4fdc5",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook implements a RAG system that:\n",
    "\n",
    "Scrapes job listings from Fusemachines using Selenium.\n",
    "- Preprocesses the data into chunks.\n",
    "- Embeds chunks using ollama’s bge-base-en-v1.5-gguf model.\n",
    "- Retrieves relevant jobs using cosine similarity.\n",
    "- Generates responses with Llama-3.2-1B-Instruct-GGUF.\n",
    "\n",
    "## Improvements:\n",
    "\n",
    "- Use a scalable vector database (e.g., Qdrant, Pinecone).\n",
    "- Implement reranking for better retrieval.\n",
    "- Scrape additional job details (e.g., descriptions) for richer context.\n",
    "- Use a larger LLM for improved response quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
